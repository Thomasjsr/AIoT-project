{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 # Computer vision\n",
    "import numpy as np # array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to classify coins and banknotes we first need to feed training data to our model.\n",
    "We first list all the paths to our images, then indecate the categories we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_datadir_train = '../coins-dataset/classified/train'\n",
    "coin_datadir_test = '../coins-dataset/classified/test'\n",
    "note_datadir_train = '../banknote-dataset/classified/train'\n",
    "note_datadir_test = '../banknote-dataset/classified/test'\n",
    "\n",
    "categories = ['1c', '2c', '5c', '10c', '20c', '50c', '1e', '2e', '5e', '10e', '20e', '50e']\n",
    "coin_index = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways we could train our model, either by the dimensions of the coin or banknote (which can be very accurate) or by analyzing all the different color variations. To keep this simple there we will be analyzing the color variations.\n",
    "\n",
    "To be able to analyze the colors of the photos, we made a loop that goes through all the photos and adds a list of the RGB values ​​of each photo into a list: training_data that contains a tuple of the RGB values and it's label indacating the category it belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img):\n",
    "    dim = (150, 150)\n",
    "    new_img = cv2.resize(img, dim)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "\n",
    "#add coins\n",
    "for category in categories[:coin_index]:\n",
    "    path = os.path.join(coin_datadir_train, category)\n",
    "    label = 0\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))\n",
    "        training_data.append([img_array, label])\n",
    "\n",
    "#add notes\n",
    "for category in categories[coin_index:]:\n",
    "    path = os.path.join(note_datadir_train, category)\n",
    "    label = 1\n",
    "    for img in os.listdir(path):\n",
    "        img_array = resize_img(cv2.imread(os.path.join(path, img)))\n",
    "        training_data.append([img_array, label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same with seperate images to test the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "\n",
    "\n",
    "#add coins\n",
    "for category in categories[:coin_index]:\n",
    "    path = os.path.join(coin_datadir_test, category)\n",
    "    label = 0\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))\n",
    "        testing_data.append([img_array, label])\n",
    "\n",
    "#add notes\n",
    "for category in categories[coin_index:]:\n",
    "    path = os.path.join(note_datadir_test, category)\n",
    "    label = 1\n",
    "    for img in os.listdir(path):\n",
    "        img_array = resize_img(cv2.imread(os.path.join(path, img)))\n",
    "        testing_data.append([img_array, label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the seperate the labels from the RGB values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)\n",
    "    \n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for features, label in testing_data:\n",
    "    x_test.append(features)\n",
    "    y_test.append(label)\n",
    "    \n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes the RGB values of an image as input and then calculates the Euclidean distance between the image and all the other images in the training_data list. The k shortest distances are put in the votes list and then finally the function outputs the label that comes out the most often between the k iamges closest to the image whose value we want to know\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def k_nearest_neighbors(predict, k):\n",
    "    distances = []\n",
    "    for image in training_data:\n",
    "        distances.append([np.linalg.norm(image[0] - predict), image[1]]) # calcul de distance euclidienne\n",
    "    distances.sort()\n",
    "    votes = [i[1] for i in distances[:k]]\n",
    "    votes = ''.join(str(e) for e in votes)\n",
    "    votes = votes.replace(',', '')\n",
    "    votes = votes.replace(' ', '')\n",
    "    result = Counter(votes).most_common(1)[0][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then test our model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occured\n",
      "527.3811609745026\n",
      "0.931454196028187\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "correct = 0\n",
    "total = 0\n",
    "skipped = 0\n",
    "for i in range(len(x_test)+1):\n",
    "    try:\n",
    "        prediction = k_nearest_neighbors(x_test[i], 5)\n",
    "        if int(prediction) == y_test[i]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    except Exception as e:\n",
    "        print('An exception occured')\n",
    "        skipped += 1\n",
    "accuracy = correct/total\n",
    "end = time()\n",
    "print(end-start)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fianly we ask the user to upload an image and use our model to predict the value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coin\n"
     ]
    }
   ],
   "source": [
    "import tkinter.filedialog\n",
    "from tkinter import *\n",
    "\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "root.update()\n",
    "filename = tkinter.filedialog.askopenfilename(title=\"Ouvrir fichier\", filetypes=[('all files', '.*')]) # sélectionner la photo\n",
    "src = cv2.imread(cv2.samples.findFile(filename), cv2.IMREAD_COLOR) # charger la photo\n",
    "root.destroy()\n",
    "\n",
    "img = resize_img(src)\n",
    "pred = k_nearest_neighbors(img, 10)\n",
    "if pred == '0':\n",
    "    print('Coin')\n",
    "else:\n",
    "    print('Banknote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
